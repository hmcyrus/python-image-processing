{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust Contrast and Brightness\n",
    "\n",
    "\n",
    "we commonly used point processes are multiplication and addition with a constant:\n",
    "\n",
    "    g(x)=αf(x)+β\n",
    "    The parameters α>0 and β are often called the gain and bias parameters; sometimes these parameters are said to control contrast and brightness respectively.\n",
    "\n",
    "    You can think of f(x) as the source image pixels and g(x) as the output image pixels. Then, more conveniently we can write the expression as:\n",
    "\n",
    "    g(i,j)=α⋅f(i,j)+β\n",
    "\n",
    "    where i and j indicates that the pixel is located in the i-th row and j-th column.\n",
    "    \n",
    "    long way:\n",
    "    for y in range(image.shape[0]):\n",
    "    for x in range(image.shape[1]):\n",
    "        for c in range(image.shape[2]):\n",
    "            new_image[y,x,c] = np.clip(alpha*image[y,x,c] + beta, 0, 255)\n",
    "            \n",
    " You can find more information here: https://docs.opencv.org/3.4/d3/dc1/tutorial_basic_linear_transform.html\n",
    " \n",
    " \n",
    " ### Task 1: Please change the brighness and the contrast of an image\n",
    " \n",
    " Find values to display vessel structures in image CONTRAST_1_CT.tif\n",
    " \n",
    "by using \n",
    "            \n",
    "            OPtion 1\n",
    "            \n",
    "            img = cv2.imread([image],cv2.IMREAD_UNCHANGED)\n",
    "            new_image = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "            \n",
    "            Option 2\n",
    "            alpha 1  beta 0      --> no change  \n",
    "            0 < alpha < 1        --> lower contrast  \n",
    "            alpha > 1            --> higher contrast  \n",
    "            -127 < beta < +127   --> good range for brightness values\n",
    "            import cv2\n",
    "            img = cv2.imread('input.png')\n",
    "            # call addWeighted function. use beta = 0 to effectively only operate one one image\n",
    "            new_image = cv2.addWeighted( img, contrast, img, 0, brightness)\n",
    "            output = cv2.addWeighted\n",
    "            \n",
    "            ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrast stretching\n",
    " use this image 'contrast_stretching.png'.\n",
    "        \n",
    "        b = im.max() \n",
    "        a = im.min() \n",
    "        # Converting im1 to float. \n",
    "        c = im.astype(float) \n",
    "        # Contrast stretching transformation. \n",
    "        im1 = 255.0*(c-a)/(b-a) \n",
    "        \n",
    "        What happens afterwards with the image?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equalization\n",
    "\n",
    "\n",
    "Equalize both images.'contrast_stretching.png'; CONTRAST_1_CT.tif\n",
    "What do you see? Plot the histograms and CDF.\n",
    "\n",
    "You can use: \n",
    "        \n",
    "        img =  cv2.imread('',0)\n",
    "        equ = cv2.equalizeHist(img)\n",
    "        res = np.hstack((img,equ)) #stacking images side-by-side\n",
    "\n",
    "        or\n",
    "        \n",
    "        hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_m = np.ma.masked_equal(cdf,0)\n",
    "        cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "        cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "        img2 = cdf[img]\n",
    "\n",
    "\n",
    "\n",
    "to plot cdf:\n",
    "        \n",
    "        hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "        plt.plot(cdf_normalized, color = 'b')\n",
    "        plt.hist(img.flatten(),256,[0,256], color = 'r')\n",
    "        \n",
    "        plt.xlim([0,256])\n",
    "        plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLAHE (Contrastive Limited Adaptive Equalization)\n",
    "\n",
    "Use CLAHE for the image  'contrast_stretching.png'. What happens? Save the image with the best contrast: best_contrast.png\n",
    "\n",
    "        #clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))# code loops through each element in the PDF, and determines whether or not that element of the PDF is greater than the clipLimit\n",
    "        cl1 = clahe.apply(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding\n",
    "\n",
    "Create a Mask for the lungs by using a threshold in image: best_contrast.png\n",
    "\n",
    "You can Use: \n",
    "        \n",
    "        t = [value]\n",
    "        binary_mask = img < t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image matching\n",
    "\n",
    "Match the images contrast_stretching.png and best_contrast.png. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# construct a figure to display the histogram plots for each channel\n",
    "# before and after histogram matching was applied\n",
    "(fig, axs) =  plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "# loop over our source image, reference image, and output matched\n",
    "# image\n",
    "for (i, image) in enumerate((src, ref, matched)):\n",
    "    # convert the image from BGR to RGB channel ordering\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # loop over the names of the channels in RGB order\n",
    "    for (j, color) in enumerate((\"red\", \"green\", \"blue\")):\n",
    "    # compute a histogram for the current channel and plot it\n",
    "        (hist, bins) = exposure.histogram(image[..., j],\n",
    "        source_range=\"dtype\")\n",
    "        axs[j, i].plot(bins, hist / hist.max())\n",
    "        # compute the cumulative distribution function for the\n",
    "        # current channel and plot it\n",
    "        (cdf, bins) = exposure.cumulative_distribution(image[..., j])\n",
    "        axs[j, i].plot(bins, cdf)\n",
    "        # set the y-axis label of the current plot to be the name\n",
    "        # of the current color channel\n",
    "        axs[j, 0].set_ylabel(color)\n",
    "# set the axes titles\n",
    "axs[0, 0].set_title(\"Source\")\n",
    "axs[0, 1].set_title(\"Reference\")\n",
    "axs[0, 2].set_title(\"Matched\")\n",
    "# display the output plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
